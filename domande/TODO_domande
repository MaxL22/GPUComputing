Pseudocodice per varie pattern possibili?
    Ad esempio: uso degli stream, uso della smem
Da fare anche per python, qualche idea base

- MLP in cuda, descrivi un layer a piacere

Domande per sezione, si ringrazia Chad Gepete:


6. Numba
In che modo Numba supporta i streams e il parallelismo dinamico?
Quali limitazioni ha Numba rispetto alla programmazione CUDA C++?
Come si ottimizza il kernel Numba per ridurre il register spilling?
Descrivi un esempio di uso di Numba per un prefix-sum.
Quando conviene usare Numba per prototipazione rapida?
Qual è l’impatto delle compile-time annotations sulla performance?
In cosa differisce la gestione della memoria tra host e device in Numba?
Come si sincronizza l’esecuzione tra host e device in Numba?
Quali tool di profiling si possono usare con Numba?
Come integrare codice CUDA C++ esistente in un progetto Numba?
Descrivi un caso di uso di Numba per l’elaborazione di immagini.
Quali pattern di accesso a memoria vanno ottimizzati in Numba?
Come si misura il tempo di esecuzione dei kernel Numba?
Quali vantaggi offre Numba nell’ambito del machine learning?
In che casi non è consigliato usare Numba GPU?
Quali best practice seguire per scrivere kernel Numba efficienti?

7. PyTorch
Come vengono rappresentati i tensori in PyTorch e in che modo supportano la GPU?
Quali operazioni fondamentali si possono eseguire sui tensori?
Come si trasferisce un tensore sulla GPU in PyTorch?
Qual è la differenza tra .to(device) e .cuda()?
Descrivi il funzionamento del modulo nn per costruire reti neurali.
Come funziona la discesa del gradiente in PyTorch?
Cos’è Autograd e come traccia le operazioni sui tensori?
In che modo PyTorch gestisce la differenziazione automatica?
Come implementare un MLP usando torch.nn.Sequential?
Qual è il ruolo degli optimizer in PyTorch e come si configurano?
Come si definisce una funzione di perdita custom?
Quali metodi esistono per salvare/caricare modelli PyTorch?
Come si esegue il multithreading nel DataLoader?
In che modo si possono sfruttare le GPU multiple in PyTorch?
Quali strumenti di profiling offre PyTorch per le GPU?
Come utilizzare i tensorboard logger con PyTorch?
Descrivi un esempio di training di un MLP su dati sintetici.
Come si misura il throughput di training in PyTorch?
Quali accorgimenti prendere per evitare l’out of memory sulla GPU?
In che modo PyTorch sfrutta la unified memory su sistemi recenti?
