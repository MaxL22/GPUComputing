% !TeX spellcheck = it_IT
\section{Sincronizzazione}

\begin{questions}
    \question Quali sono i meccanismi di sincronizzazione?
    
    \begin{solution}
        Si possono avere più \textbf{livelli di sincronizzazione}:
        \begin{itemize}
            \item \textbf{Livello di sistema}: per attendere che un dato task venga completato su host e device; la primitiva
            \begin{minted}{cuda}
cudaError_t cudaDeviceSynchronize();
            \end{minted}
            blocca l'applicazione host finché tutte le operazioni CUDA su tutti gli stream non sono completate. Si tratta di una funzione host-side only (una volta usata lato device per gestire il parallelismo dinamico, ma ora deprecata);
            
            \item Non c'è una primitiva esplicita per la sincronizzazione a \textbf{livello di grid}, ma la si può ottenere (da CC 6 in avanti) lanciando un kernel cooperativo
            \begin{minted}{cuda}
cudaLaunchCooperativeKernel(
    (void*) myKernel,
    gridDim, blockDim,
    kernelArgs, /*sharedMemBytes=*/0, /*stream=*/0);
            \end{minted}
            e all'interno del kernel
            \begin{minted}{cuda}
grid_group grid = this_grid();
// work work work ...
// waits for _all_ blocks in *this* kernel
grid.sync();
            \end{minted}
            Non ci devono essere ulteriori kernel attivi all'interno del device;
            
            \item \textbf{Livello di blocco}: per attendere che tutti i thread in un blocco raggiungano lo stesso punto di esecuzione. La primitiva
            \begin{minted}{cuda}
__syncthreads();
            \end{minted}
            impone a tutti i thread nel blocco corrente di attendere fino a quando tutti gli altri thread dello stesso blocco non hanno raggiunto quel particolare punto di esecuzione. Lo scopo principale è garantire la visibilità degli accessi alla memoria (rendere visibile le modifiche), in modo da evitare conflitti e race conditions. Se non tutti i thread all'interno del blocco arrivano alla primitiva si può avere un deadlock;
            
            \item \textbf{Livello di warp}: per attendere che tutti i thread all'interno di un warp raggiungano lo stesso punto di esecuzione. La primitiva
            \begin{minted}{cuda}
__syncwarp(mask);
            \end{minted}
            permette di avere una barriera esplicita per garantire la ri-convergenza del warp per le istruzioni successive. L'argomento \texttt{mask} è composto da una sequenza di 32 bit che permette di definire quali warp partecipano alla sincronizzazione (se omessa, di default tutti, ovvero \texttt{0xFFFFFFFF}).
        \end{itemize}
        
        Sincronizzazione \textbf{tramite stream}: tra stream non-NULL diversi non si ha nessuna dipendenza od ordinamento, mentre lo stream di default (\texttt{0}) ha un comportamento diverso, può essere: 
        \begin{itemize}
            \item \texttt{legacy}: bloccante rispetto a tutti gli altri stream, un'operazione lanciata nel default stream non può iniziare finché non sono completate tutte le operazioni precedenti in qualsiasi altro stream (e viceversa);
            
            \item \texttt{per-thread}: disponibile da CUDA 7, ogni thread host ottiene il suo default stream, diventa non-bloccante rispetto agli altri stream
        \end{itemize}
        Il comportamento può essere configurato tramite parametro \texttt{--default-stream} durante compilazione o direttiva nel codice.
        
        Sincronizzazione \textbf{tramite eventi}: all'interno degli stream si possono creare degli eventi tramite i quali è possibile avere anche sincronizzazione:
        \begin{itemize}
            \item Host-side: la primitiva
            \begin{minted}{cuda}
cudaError_t cudaEventSynchronize(cudaEvent_t event);
            \end{minted}
            permette di attendere lato host finché l'evento specificato non viene completato; esiste una variante non-bloccante:
            \begin{minted}{cuda}
cudaError_t cudaEventQuery(cudaEvent_t event);
            \end{minted}
            che permette di controllare se un evento è stato completato o meno, senza bloccare l'host;
            
            \item Stream-to-stream: per far attendere a uno stream il completamente di un evento su un altro stream. La primitiva:
            \begin{minted}{cuda}
cudaError_t cudaStreamWaitEvent(
    cudaStream_t stream, cudaEvent_t event);
            \end{minted}
            permette di aspettare un evento su un altro stream (anche su altri device).
        \end{itemize}
        
        Sincronizzazione \textbf{implicita} dovuta a operazioni bloccanti: alcune operazioni causano sincronizzazione in quanto implicano un blocco su tutte le operazioni precedenti sul device corrente. In questo gruppo rientrano molte operazioni relative alla gestione della memoria.
    \end{solution}
    
    \question Meccanismi di sincronizzazione tra GPU e modalità di trasmissione tra queste \footnote{Da notare che la parte di multi-GPU non è più trattata nel corso}.
    
    \begin{solution}
        Tra diverse GPU ci sono più metodi di \textbf{sincronizzazione} possibili: 
        \begin{itemize}
            \item Il metodo più semplice è lasciare che sia l'host a sincronizzare tutte le GPU, la primitiva \texttt{cudaDeviceSynchronize()} permette di attendere il completamento di tutte le operazioni su tutte le GPU (il comando va ripetuto per ogni device)
            
            \item Per una gestione più flessibile si possono usare gli eventi CUDA; un evento è un marcatore all'interno di una stream su un device, un'altra GPU può "ascoltare" per attendere il completamento di un evento su un altro device, tramite \texttt{cudaStreamWaitEvent()} (bloccante) o \texttt{cudaStreamQueryEvent()} (non bloccante)
            
            \item La libreria NCCL (Nvidia Collective Communications Library) fornisce primitive di comunicazione con sincronizzazione implicita
        \end{itemize}
        
        Anche per \textbf{trasmettere dati} tra più GPU ci sono diverse modalità:
        \begin{itemize}
            \item La più semplice è via host: i dati vengono copiati sull'host e poi passati ai device a cui servono (tramite \texttt{cudaMemcpy()})
            
            \item Se il P2P è abilitato, esistono primitive che permettono lo scambio dati tra GPU diverse, come ad esempio \texttt{cudaMemcpyPeer()}; esistono anche primitive asincrone come \texttt{cudaMemcpyAsync()} e \texttt{cudaMemcpyPeerAsync()}
            
            \item Usare unified memory: la memoria unificata permette di avere uno spazio di indirizzamento condiviso tra host e device, allocando con \texttt{cudaMallocManaged()} si può usare lo stesso puntatore su tutti i dispositivi
            
            \item Per primitive di comunicazione altamente ottimizzate per la comunicazione collettiva la libreria NCCL offre throughput elevato e bassa latenza
        \end{itemize}
    \end{solution}
    
    \question Sincronizzazione tra più device che condividono lo stesso bus \footnote{Come sopra}.
    
    \begin{solution}
        La sincronizzazione tramite stream ed eventi si può usare anche tra diversi device: un device può controllare il completamento di un evento appartenente a uno stream in esecuzione su un diverso device. La primitiva
        \begin{minted}{cuda}
cudaError_t cudaEventSynchronize(cudaEvent_t event);
        \end{minted}
        permette di attendere l'esecuzione di un evento in maniera bloccante, altrimenti
        \begin{minted}{cuda}
cudaError_t cudaEventQuery(cudaEvent_t event);
        \end{minted}
        permette di controllare se l'evento è completato o meno in maniera non bloccante.
        
        Rimane sempre un'opzione la sincronizzazione host-side, effettuabile tramite la primitiva \texttt{cudaDeviceSynchronize()} per ogni dispositivo.
        
        Esistono inoltre primitive di sincronizzazione esplicite per kernel cooperativi multi-device (\texttt{this\_grid().sync()}).
        
        La libreria NCCL (Nvidia Collective Communications Library) per la comunicazione collettiva fornisce primitive con sincronizzazione implicita al loro interno.
    \end{solution}
    
    \question Cos'è la divergenza e qual è la sua relazione con la sincronizzazione a livello di blocco.
    
    \begin{solution}
        La divergenza è un fenomeno per cui i thread all'interno di uno stesso warp (gruppo di 32 thread) seguono percorsi di esecuzione diverse a causa di istruzioni di branching (\texttt{if}, \texttt{switch}, \dots). Questo porta a un degrado delle performance in quanto i flussi di esecuzione diversi sono eseguiti in modo seriale dall'hardware, disattivando i thread "non interessati".
        
        CUDA fornisce primitive per la sincronizzazione esplicita a livello di blocco: 
        \begin{minted}{cuda}
__syncthreads();
        \end{minted}
        Ovvero una barriera che devono raggiungere tutti i thread prima che la computazione possa proseguire.
        
        Se una primitiva \texttt{\_\_syncthreads()} è "nascosta" dietro a istruzioni condizionali e non viene raggiunta da tutti i thread del blocco si incorre in un deadlock: i thread che hanno raggiunto l'istruzione rimarranno fermi, gli altri non la raggiungeranno mai; la correttezza dell'uso sta al programmatore.
        
        Non si può risolvere la divergenza a livello di blocco, anche se la sincronizzazione è posta in maniera corretta (non causa deadlock), la serializzazione dei percorsi di esecuzione avviene ugualmente. 
        
        Per risolvere le divergenze si possono usare primitive di sincronizzazione a livello di warp (\texttt{\_\_syncwarp()}) o tecniche per evitare del tutto istruzioni condizionali.
    \end{solution}
    
    \question Cosa sono e per cosa possono essere utilizzati gli eventi.
    
    \begin{solution}
        Un evento è un marker all'interno di uno stream associato a un punto del flusso di operazioni. Possono assumere due stati: occorso/non occorso. I due utilizzi principali sono: 
        \begin{itemize}
            \item Sincronizzare l'esecuzione tra stream: si può avere sincronizzazione esplicita tra stream tramite gli eventi, la primitiva
            \begin{minted}{cuda}
cudaError_t cudaStreamWaitEvent(
    cudaStream_t stream , cudaEvent_t event);
            \end{minted}
            permette di far attendere a uno stream l'occorrenza di un evento su un altro stream (non necessariamente sulla stessa GPU)
            
            \item Monitorare il progresso del device: dal lato host si possono usare le primitive
            \begin{minted}{cuda}
cudaError_t cudaEventSynchronize(cudaEvent_t event);
cudaError_t cudaEventQuery(cudaEvent_t event);
            \end{minted}
            per, rispettivamente, bloccare l'host fino all'occorrenza di un evento oppure controllarne l'avvenimento in maniera non bloccante
        \end{itemize}
    \end{solution}
    
\end{questions}