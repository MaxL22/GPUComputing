% !TeX spellcheck = it_IT
\section{PyTorch}

PyTorch è un framework open source per il ML, sviluppato principalmente da Facebook AI, combina un backend accelerato dalla GPU con frontend Python. 

Il core di PyTorch viene usato per implementare tensori, strutture dati, operatori CPU e GPU, primitive parallele e calcoli differenziali. Il core è la parte più computazionalmente intensiva, ma può essere implementata in C++ per le performance.

Si ha una separazione netta tra control e data flow: il controllo è solamente Python, il data flow è codice C++ il quale può essere eseguito sia su CPU che GPU.

PyTorch è compatibile con librerie e pacchetti popolari come NumPy, SciPy e Numba.

\subsection{Tensori}

PyTorch funziona principalmente attraverso i \textbf{tensori}, strutture dati simili ad array e matrici, ma $n$ dimensionali. I tensori vengono usati per codificare input, output e parametri del modello.

In breve, sono "matrici", senza un limite stretto sul numero di dimensioni.

I tensori possono essere inizializzati in diversi modi: 
\begin{itemize}
    \item Per creare un \textbf{tensore vuoto}:
    \begin{minted}{python}
t  = torch.empty(x, y)
    \end{minted}
    i parametri sono le dimensioni
    
    \item Ma spesso li si vuole inizializzare con un \textbf{valore}, tipicamente 0,1 oppure casuali:
    \begin{minted}{python}
t = torch.zeros(x, y)
t = torch.ones(x, y)
t = torch.rand(x, y)
    \end{minted}
    
    \item Per inizializzare un tensore con la \textbf{stessa forma di un altro}:
    \begin{minted}{python}
t = torch.empty_like(another_tensor)
t = torch.zeros_like(another_tensor)
t = torch.ones_like(another_tensor)
t = torch.rand_like(another_tensor)
    \end{minted}
    
    \item Per creare un tensore inizializzato tramite una \textbf{struttura dati esistente}:
    \begin{minted}{python}
vector = torch.tensor([7, 7])
matrix = torch.tensor([[7, 8], [9, 10]])
    \end{minted}
    
    \item Si può creare un \textbf{vettore 1D} con tutti i valori da \texttt{0} a \texttt{end-1} tramite \texttt{torch.arange(end)}, lo si può poi \textbf{vedere} o \textbf{ridimensionare} con altre forme:
    \begin{minted}{python}
t = torch.arange(end).view(x, y)
t = torch.arange(end).reshape(x, y)
    \end{minted}
\end{itemize}

Il tipo di default è \texttt{f32}, ma lo si può sovrascrivere tramite il parametro \texttt{dtype}. Ad esempio:
\begin{minted}{python}
t = torch.ones((x, y), dtype=torch.int16)
\end{minted}

All'interno della memoria fisica, i tensori sono sempre memorizzati in maniera linearizzata e contigua. Lo si può anche vedere tramite
\begin{minted}{python}
t.storage()
\end{minted}

\subsection{Operazioni}

All'interno della libreria sono presenti numerose ($> 100$) operazioni di aritmetica, algebra lineare, operazioni su matrici, \dots

Permette indicizzamento e slicing in maniera analoga a NumPy. Si può anche indicizzare in più dimensioni tramite il simbolo "\texttt{:}"
\begin{minted}{python}
t[:, 0, 0]
\end{minted}
restituisce l'elemento in alto a sinistra di ogni elemento presente all'interno del tensore. Ovviamente si possono anche accedere elementi arbitrari in ogni dimensione.

\paragraph{Broadcasting:} Da NumPy viene copiato il broadcasting, se le dimensioni non coincidono, il risultato "estende" gli elementi del più piccolo. Esempio:
\begin{center}
    \begin{tabular}{| c | c | c |}
        \hline 
        \texttt{1} & \texttt{2} & \texttt{3} \\
        \hline
    \end{tabular}
    $\cdot$
    \begin{tabular}{| c |}
        \hline
        \texttt{2} \\
        \hline 
    \end{tabular}
    $=$ 
    \begin{tabular}{| c | c | c |}
        \hline
        \texttt{2} & \texttt{4} & \texttt{6} \\
        \hline
    \end{tabular}
\end{center}

\subsubsection{Spostarli sulla GPU}

Gli attributi di un tensore sono: forma, tipo di dato e \textbf{dispositivo su cui si trova}; quest'ultimo può essere CPU o GPU. Di default, i tensori vengono creati sulla GPU. Se disponibile, vorremmo sfruttare il backend più efficiente dato dalla GPU. 

Per vedere se una GPU è disponibile ed eventualmente i parametri della GPU in uso:
\begin{minted}{python}
print(torch.cuda.is_available()) # Check CUDA availability
print(torch.cuda.current_device()) # Current CUDA device
print(torch.cuda.get_device_name(0)) # Name of the device
\end{minted}

Dopo aver controllato che un device sia disponibile, si possono muovere i tensori su di esso
\begin{itemize}
    \item in fase di creazione, tramite il parametro \texttt{device}
    
    \item tramite il metodo \texttt{.to(dst)}, dove \texttt{dst} è il dispositivo di destinazione
\end{itemize}

Esempi:
\begin{minted}{python}
cuda = torch.device('cuda:0')

t1 = torch.tensor([1, 2, 3], device=cuda)

t2 = torch.tensor([1, 2, 3])
t_g = t2.to(cuda)
\end{minted}

\subsection{Linear Neural Networks}

\paragraph{Regressione:} La regressione lineare vuole modellare il rapporto tra una variabile dipendente $y$ (output) e una (o più) variabile (/i) indipendenti $x$ (input). Le assunzioni sono: 
\begin{itemize}
    \item relazione lineare tra $x$ e $y$
    
    \item il rumore segue una distribuzione Gaussiana
\end{itemize}

\paragraph{Loss function:} L'obiettivo della regressione è minimizzare una funzione di errore, la quale quantifica la distanza tra valore reale $y^{(i)}$ e valore predetto dalla regressione ottenuta $\hat y^{(i)}$.

Squared loss: l'errore quadratico si può calcolare su una singola entry $i$ come:
$$ \ell^{(i)} = (\bm w, b) = \frac{1}{2}  \left(\hat y_i - y_i\right)^2 $$

Mentre su tutto il dataset:
$$ L (\bm w, b) = \frac{1}{n} \sum_{i=1}^{n} \ell^{(i)} (\bm w, b) = \frac{1}{n} \sum_{i=1}^{n} \frac{1}{2} \left(\bm w^T x_i - y_i \right)^2 $$

%I parametri saranno scalari PyTorch, il broadcasting farà ottenere tensori.

\subsubsection{Discesa del gradiente}

Si vuole ottimizzare la loss function rispetto ai parametri, utilizzando l'algoritmo di \href{https://it.wikipedia.org/wiki/Discesa_del_gradiente}{\texttt{gradient descent}}. L'idea è di calcolare il rate di cambiamento della loss function rispetto a ogni parametro e modificare ciascuno di questi nella direzione che porta a ridurre la loss il più possibile.

Bisogna decidere un $\delta$ che determina "quanto lontano guardare" sulla loss function per determinare la direzione in cui decresce di più; se i parametri variano troppo in fretta rispetto alla loss function potrebbe essere difficile capire in che direzione l'errore si riduce maggiormente.

Va determinato anche un learning rate $\eta$ che determina di quanto variare i parametri al termine dell'iterazione, sempre secondo la direzione determinata precedentemente.

\href{it.wikipedia.org/wiki/Gradiente}{\texttt{Se vuoi sapere come si calcola il gradiente.}}

Si vuole calcolare la derivata della loss rispetto a un parametro, per farlo possiamo applicare la chain rule e calcolare la derivata della loss rispetto al suo input moltiplicato la derivata del modello $m$ (si intende il modello della funzione usata per fare la regressione, in questo caso lineare, quindi $wx + b$) rispetto al parametro.
$$ \nabla_{w,b} = \left( \frac{\partial L}{\partial w}, \frac{\partial L}{\partial b}\right) = \left(\frac{\partial L}{\partial m} \cdot \frac{\partial m}{\partial w}, \frac{\partial L}{\partial m} \cdot \frac{\partial m}{\partial b}\right) $$

Dopo aver inizializzato i parametri, li si aggiornano finché $\bm w$ e $b$ non cambiano più (variazione al di sotto di un $\epsilon$), oppure si fissa un numero massimo di iterazioni (ci sono altre termination conditions possibili, ma sticazzi).

Se l'aggiornamento dei parametri è troppo grande, si può avere un'oscillazione eccessiva del modello e conseguente divergenza del training.

\paragraph{Normalizzazione:} I gradienti di matrice dei pesi e bias sono solitamente su ordini di grandezza diversi, rendendo un solo learning rate inefficace. 

Al posto che usare più learning rate diversi, si normalizzano i valori all'interno di un range.

\paragraph{Sequential lerning:} Al posto che processare l'intero data set assieme, si può considerare un punto per volta, aggiornando i parametri dopo ognuno di questi (online learning).

Esempio di algoritmo di apprendimento sequenziale è stochastic (sequential) gradient descent. 

I modelli vengono addestrati facendo training: con questo termine si intende un'ottimizzazione iterativa dell'algoritmo che aggiorna i parametri in una direzione che decresce la error function man mano.

\paragraph{Algoritmo gradient descent:} Un possibile algoritmo:
\begin{enumerate}
    \item Inizializzazione random dei pesi, scegliere un learning rate $\eta$
    
    \item Fino a convergenza ripetere:
    \begin{itemize}
        \item Calcolare il gradiente
        $$ \frac{\partial L (\bm w)}{\partial \bm w} $$
        
        \item Aggiornare i pesi
        $$ \bm w \leftarrow \bm w - \eta \frac{\partial L (\bm w)}{\partial \bm w} $$
    \end{itemize}
    
    \item Ritorna i valori $\bm w$
\end{enumerate}
Downside: calcolare il gradiente di $L$ su tutto il training set per un singolo update è troppo costoso.

\paragraph{Minibatch Stochastic Gradient Descent (SGD):} Come prima, ma batch più piccoli: 
\begin{enumerate}
    \item Inizializza casualmente i valori
    
    \item Ripetere fino a convergenza:
    \begin{itemize}
        \item Scegliere un minibatch $\beta$ (subset degli esempi di training)
        
        \item Calcolare il gradiente di $L$ ristretto su $\beta$:
        $$ \partial_{\bm w, b} \ell^{(i)} (\bm w, b) $$
        
        \item Aggiornare i parametri 
        $$ (\bm w, b) \leftarrow (\bm w, b) - \frac{\eta}{|\beta|} \sum_{i \in \beta} \partial_{\bm w, b} \ell^{(i)} (\bm w, b) $$
    \end{itemize}
\end{enumerate}

Come scegliamo learning rate $\eta$ e dimensione del minibatch $|\beta|$? Possono essere specificati manualmente, con poi eventuale tuning. In generale non possono essere troppo piccoli (troppo tempo, workload troppo piccolo) o troppo grandi (oscillazioni, problemi di memoria).

\subsubsection{Autograd}

Autograd di PyTorch è un componente che automatizza il calcolo della discesa del gradiente. Permette backpropagation automatica, ogni tensore "ricorda" lo storico delle sue operazioni; calcolare manualmente le derivate è inutile.

Per applicare autograd, è necessario riscrivere modello e loss function usando \texttt{requires\_grad=True} e chiamare \texttt{.backward()} on the loss.

Ogni tensore derivato da uno con \texttt{requires\_grad=True} manterrà uno storico delle sue computazioni. 

Dopo aver chiamato \texttt{.backward()}, PyTorch calcola automaticamente il gradiente in \texttt{.grad} (se differenziabile). 

\paragraph{Altri optimizer:} Oltre al classico gradient descent, si possono utilizzare altri modelli di ottimizzazione, tramite \texttt{torch.optim}.

Ogni optimizer PyTorch espone due metodi core: 
\begin{itemize}
    \item \texttt{zero\_grad()}: elimina tutti i \texttt{.grad} gestiti dall'optimizer
    
    \item \texttt{step()}: aggiorna i parametri dei valori basandosi sull'algoritmo scelto
\end{itemize}

Esempio: 
\begin{minted}{python}
optimizer = torch.optim.SGD(params, lr=learning_rate)
\end{minted}

\subsection{Multi Layer Perceptron MLP}

Reti neurali con un solo layer sono limitati, usiamo i \href{https://it.wikipedia.org/wiki/Percettrone_multistrato}{\texttt{Multilayer Perceptrons}}, per avere più espressività.

Dai che lo sai come funzionano.

\subsubsection{Modulo nn}

PyTorch fornisce un modulo \texttt{nn} dedicato alla costruzione di reti neurali.

Possiamo mantenere invariata la loss function ma ridefinire il modello usando semplici reti neurali. Il nuovo modello include: 
\begin{itemize}
    \item un modulo lineare
    
    \item una funzione di attivazione, generalmente non lineare (hidden layer)
    
    \item un altro modulo lineare per produrre l'output
\end{itemize}

Anche se input e output sono entrambi scalari, generalmente l'hidden layer ha più di una unità, fornendo maggiori capacità al modello.

Il layer finale combina le attivazioni linearmente per produrre l'output finale.

Il modulo \texttt{nn} fornisce una maniera semplice per concatenare moduli tramite il container \texttt{nn.Sequential}. Esempio: 
\begin{minted}{python}
seq_model = nn.Sequential(
    nn.Linear(1, 13),
    nn.Tanh(),
    nn.Linear(13, 1))
\end{minted}

%check maybe?